batch_size: 1
data_module:
  _target_: speechllm.data.datamodule.BasicDataModule
  train_dataloader_args:
    batch_size: ${data_module.batch_size}
    collate_fn:
      _partial_: true
      _target_: speechllm.data.collate.collate
      tokenizer:
        _target_: speechllm.data.utils.get_tokenizer
        model_fpath: ${paths.pretrained_models}/AnyGPT-chat
        offline: ${offline}
    drop_last: true
    num_workers: ${data_module.num_workers}
    persistent_workers: ${data_module.persistent_workers}
    pin_memory: ${data_module.pin_memory}
    prefetch_factor: ${data_module.prefetch_factor}
  train_dataset: ${data_module.train_dataset}
  val_dataloader_args:
    batch_size: ${data_module.batch_size}
    collate_fn:
      _partial_: true
      _target_: speechllm.data.collate.collate
      tokenizer:
        _target_: speechllm.data.utils.get_tokenizer
        model_fpath: ${paths.pretrained_models}/AnyGPT-chat
        offline: ${offline}
    drop_last: true
    num_workers: 1
    persistent_workers: ${data_module.persistent_workers}
    pin_memory: ${data_module.pin_memory}
    prefetch_factor: 2
  val_dataset: ${data_module.val_dataset}
num_preprocess_workers: 16
num_workers: 2
persistent_workers: false
pin_memory: false
prefetch_factor: 2
train_dataset:
  _target_: speechllm.data.soda.pipeline.soda_asr_tts_implicit_cot_pipeline
  cache_dir: ${paths.dataset_cache}
  database: ${database.train.soda}
  num_workers: ${data_module.num_preprocess_workers}
  stage: train
val_dataset:
  _target_: speechllm.data.soda.pipeline.soda_asr_tts_implicit_cot_pipeline
  cache_dir: ${paths.dataset_cache}
  database: ${database.val.soda}
  num_workers: ${data_module.num_preprocess_workers}
  stage: val
