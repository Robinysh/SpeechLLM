
[project]
name = "speechllm"
version = "1.0.0"
description = ""
authors = [
    {name = "Robin Yuen Shing Hei", email = "robin.ysh@gmail.com"},
]
dependencies = [
    "icecream>=2.1.3",
    "tqdm>=4.66.1",
    "flake8>=6.1.0",
    "black>=23.12.1",
    "isort>=5.13.2",
    "autoflake>=2.2.1",
    "pylint>=3.0.3",
    # "transformers>=4.36.2",
    "torch==2.2.2",
    "tiktoken>=0.5.2",
    "matplotlib>=3.8.1",
    "transformers-stream-generator>=0.0.4",
    "packaging>=23.2",
    "ninja>=1.11.1.1",
    "setuptools>=69.0.3",
    "jupyterlab>=4.2.0",
    "resemble-enhance @ git+https://github.com/Robinysh/resemble-enhance-optimize",
    "soundfile>=0.12.1",
    "lightningtools @ git+https://github.com/flyingmilktea/lightningtools",
    "ray[data]>=2.9.1",
    "auto-gptq>=0.6.0",
    "grpcio>=1.62.0",
    "pyannote-audio>=3.1.1",
    "openai>=1.13.3",
    "py-cpuinfo>=9.0.0",
    "torchaudio==2.2.2",
    "torchvision==0.17.2",
    "static-ffmpeg>=2.5",
    "ipython>=8.24.0",
    "ipykernel>=6.29.4",
    "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git",
    "peft>=0.10.0",
    "samplerate>=0.2.1",
    "ijson>=3.2.3",
    "pycryptodome>=3.20.0",
    "speechtokenizer>=0.1.2",
    "beartype==0.16.4",
    "click>=8.1.7",
    "linetimer>=0.1.5",
    "galore-torch @ git+https://github.com/Robinysh/GaLore",
    "torch-warmup-lr @ git+https://github.com/Robinysh/torch-warmup-lr.git",
    "librosa>=0.10.2.post1",
    "chattts @ git+https://github.com/2noise/ChatTTS@dev",
    "tensorboard>=2.17.1",
    "ipywidgets>=8.1.3",
    "nemo-text-processing>=1.0.2",
]
requires-python = ">=3.10.0,<3.12"
readme = "README.md"
license = {text = "MIT"}

[project.optional-dependencies]
cuda = ["flash-attn>=2.5.6", "bitsandbytes>=0.42.0", "vllm"]
hpu = [
    "lightning-habana>=1.6.0",
    "deepspeed @ git+https://github.com/HabanaAI/DeepSpeed.git@1.16.2",
    "optimum[habana]>=1.12.1",
    "optimum-habana>=1.12",
    "vllm @ git+https://github.com/HabanaAI/vllm-fork.git@v0.4.1",
]

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.pdm.scripts]
#start.env = {HYDRA_FULL_ERROR="1", PT_HPU_LAZY_MODE="0", PT_HPU_AUTOCAST_LOWER_PRECISION_OPS_LIST="./src/lower_list.txt", PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES="1"}
start.env = {HYDRA_FULL_ERROR="1", PT_HPU_LAZY_MODE="0", PT_HPU_AUTOCAST_LOWER_PRECISION_OPS_LIST="./src/lower_list.txt"}
start.env_file=".env"
pdm-autoflake.shell = "git ls-files '*.py' | xargs -t pdm run autoflake --in-place --expand-star-imports --remove-all-unused-imports --ignore-init-module-imports"
pdm-isort.shell = "git ls-files '*.py' | xargs -t pdm run isort -q"
pdm-black.shell = "git ls-files '*.py' | xargs -t pdm run black -q"
lint-format-python.composite = ["pdm-autoflake", "pdm-isort", "pdm-black"]
lint-format-gitignore.shell = "git ls-files '.gitignore' | xargs -tI {} sort -o {} {}"
lint-format-yaml.shell = "git ls-files '*.yml' '*.yaml' | xargs -t yq -i -S -Y -w 10000 ."
lint-format.env = {LC_ALL="C"}
lint-format.composite = ["lint-format-python", "lint-format-gitignore", "lint-format-yaml"]
pdm-flake8.shell = "git ls-files '*.py' | xargs -t pdm run flake8"
pdm-pylint.shell = "git ls-files '*.py' | xargs -t pdm run pylint"
lint.composite = ["pdm-flake8", "pdm-pylint"]
start.shell = "pdm run python -m speechllm.main"
#start.shell = "pdm run python -m cProfile -o output.prof src/speechllm/main.py"
#data-generate.shell = "if [ -e .env ]; then pdm run python src/speechllm/data_generation/main.py; else echo 'Make a copy of .env from .env.sample before you start.'; fi"
data-generate.env = {OMP_NUM_THREADS="8", PT_HPU_LAZY_MODE="0"}
data-generate.env_file=".env"
data-generate.shell = "pdm run python src/speechllm/data_generation/gigaspeech/main.py"
pre_install.shell = "export CMAKE_ARGS='-DLLAMA_CUBLAS=on' FORCE_CMAKE=1 CFLAGS='-fPIC' CXX_FLAGS='-fPIC'"
install.env = {CMAKE_ARGS="-DLLAMA_CUBLAS=on", FORCE_CMAKE="1", CFLAGS="-fPIC", CXX_FLAGS="-fPIC"}
llm_server.shell = "python -m vllm.entrypoints.openai.api_server --model TheBloke/Mixtral_11Bx2_MoE_19B-GPTQ --gpu-memory-utilization 0.8 --dtype=half"

[tool.pdm.options]
add = ["--no-isolation"]
sync = ["--no-isolation"]
installsync = ["--no-isolation"]

[tool.pdm.resolution.overrides]
transformers = "==4.40.0"  # dependency bug with optimum-habana and unsloth
torch = "==2.2.2"  # dependency bug with habana deepspeed==2.2.2 and vllm picky version
accelerate = ">=0.28.0"  # dependency bug with speechtokenizer >= 0.28 and optimum-habana < 0.28
